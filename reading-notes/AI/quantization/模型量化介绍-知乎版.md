# [模型量化了解一下？](https://zhuanlan.zhihu.com/p/132561405)

## 量化综述
### 1. 什么是模型量化？为什么要进行模型量化？  
- **量化是指将信号的连续取值近似为有限多个离散值的过程**。可理解成一种信息压缩的方法。在计算机系统上考虑这个概念，一般用“低比特”来表示。也有人称量化为“定点化”，但是严格来讲所表示的范围是缩小的。
- `卷积神经网络明显的缺点：具有较大的参数量，计算量，以及内存占用`。<mark>量化：具有为神经网络压缩参数、提升速度、降低内存占用等"潜在"优势</mark>。
- 模型量化是一种近似算法方法，精度损失是一个严峻的问题，大部分的研究都在关注这一问题。作为一个在公司支撑很多业务线的团队，我们会在关注精度的同时，注重部署最终的速度和资源占用情况。
- 从量化数变到原始数的过程，称之为**反量化**。

### 2. 压缩参数  

### 3. 提升速度  
- 什么样的量化方法可以带来潜在、可落地的速度提升呢？我们总结需要满足两个条件：量化数值的计算在部署硬件上的峰值性能更高、量化算法引入的额外计算（overhead）少。提速概率较大的方法：`二值化、线性量化、对数量化`。

### 4. 降低内存  

### 5. 生产量化模型  

### 6. 量化模型的落地  
- 量化模型落地的挑战：
    ```
    除了精度外，软硬件支持不好也是一个阻碍：不同的硬件支持的低比特指令是不一样的，同样训练得到的低比特模型，无法直接部署在所有硬件上。除了硬件之外，不同软件库实现的量化方案和细节也不一样，量化细节里包括量化位置、是否支持perchannel、是否混合精度等等。即使硬件支持了量化，但你会发现不是所有硬件可以在低比特上提供更好的速度提升， 造成这个状况的主要原因有多个，一方面是指令集峰值提升可能本身就并不多，而要引入较多的额外计算，另一方面也取决于软件工程师优化指令的水平，同时由于网络结构灵活多样，不一定能在不同网络结构上达到同样好的加速比，需要优化足够多的的corner case才可以解决
    ```

## 论文解读
- 低比特量化  
Differentiable Soft Quantization: Bridging Full-Precision and Low-Bit Neural Networks（ICCV 2019）
- 模型二值化  
IR-Net: Forward and Backward Information Retention for Highly Accurate Binary Neural Networks（CVPR 2020）
- 8bit训练加速  
Towards Unified INT8 Training for Convolutional Neural Network（CVPR 2020）
- 低比特人脸识别
- 量化友好网络结构


# [Tensorflow模型量化(Quantization)原理及其实现方法](https://zhuanlan.zhihu.com/p/79744430) 
TODO
